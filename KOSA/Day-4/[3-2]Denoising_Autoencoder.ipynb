{"cells":[{"cell_type":"markdown","metadata":{"id":"QQ97dC_jLHvF"},"source":["# **Denoising Autoencoder Using PyTorch Framework**"]},{"cell_type":"markdown","metadata":{"id":"BX6s-j7fq3hA"},"source":["## Check NVIDIA GPU Setting"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"D_I7cz1Sq6S1","executionInfo":{"status":"ok","timestamp":1752038045481,"user_tz":-540,"elapsed":120,"user":{"displayName":"서현택","userId":"13776042586561896178"}},"outputId":"a4ed16ef-2d38-42b4-d2d3-66377c76859f","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["/bin/bash: line 1: nvidia-smi: command not found\n"]}],"source":["!nvidia-smi"]},{"cell_type":"markdown","metadata":{"id":"1sg71j-zWuau"},"source":["## Load MNIST Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UvcYeIfuWwE9"},"outputs":[],"source":["from torchvision.datasets import MNIST\n","from torchvision import transforms"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TRURIUnrW_1e"},"outputs":[],"source":["train_dataset = MNIST(root=\"content\",\n","                      train=True,\n","                      transform=transforms.Compose([transforms.Resize((32,32)), transforms.ToTensor()]),\n","                      download=True)\n","test_dataset = MNIST(root=\"content\",\n","                     train=False,\n","                     transform=transforms.Compose([transforms.Resize((32,32)), transforms.ToTensor()]),\n","                     download=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lcjb8ky2PvGo"},"outputs":[],"source":["import torch\n","from torch import nn\n","import torch.nn.functional as F"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VpMGcu1KP07P"},"outputs":[],"source":["class MyModel(nn.Module) :\n","  def __init__(self, opt) :\n","    super(MyModel, self).__init__()\n","\n","    input_dim, hidden_dim = opt[\"input_dim\"], opt[\"hidden_dim\"]\n","\n","    self.encoder = nn.Sequential(nn.Conv2d(input_dim, hidden_dim, kernel_size=3, stride=1, padding=1),\n","                                 nn.ReLU(),\n","                                 nn.MaxPool2d(kernel_size=2, stride=2),\n","                                 nn.Conv2d(hidden_dim, hidden_dim, kernel_size=3, stride=1, padding=1),\n","                                 nn.ReLU(),\n","                                 nn.MaxPool2d(kernel_size=2, stride=2),\n","                                 nn.Conv2d(hidden_dim, hidden_dim, kernel_size=3, stride=1, padding=1),\n","                                 nn.ReLU(),\n","                                 nn.MaxPool2d(kernel_size=2, stride=2),\n","                                 nn.Conv2d(hidden_dim, hidden_dim, kernel_size=3, stride=1, padding=1),\n","                                 nn.ReLU())\n","    self.decoder = nn.Sequential(nn.Conv2d(hidden_dim, hidden_dim, kernel_size=3, stride=1, padding=1),\n","                                 nn.ReLU(),\n","                                 nn.Upsample(scale_factor=2),\n","                                 nn.Conv2d(hidden_dim, hidden_dim, kernel_size=3, stride=1, padding=1),\n","                                 nn.ReLU(),\n","                                 nn.Upsample(scale_factor=2),\n","                                 nn.Conv2d(hidden_dim, hidden_dim, kernel_size=3, stride=1, padding=1),\n","                                 nn.ReLU(),\n","                                 nn.Upsample(scale_factor=2),\n","                                 nn.Conv2d(hidden_dim, input_dim, kernel_size=3, stride=1, padding=1))\n","\n","    self.bottleneck0 = nn.Linear(((opt[\"input_shape\"]//8)**2)*hidden_dim, 2)\n","    self.bottleneck1 = nn.Linear(2, ((opt[\"input_shape\"]//8)**2)*hidden_dim)\n","\n","  def forward(self, input) :\n","    noisy = torch.clamp(input+torch.randn_like(input)*(50/255), 0, 1)\n","\n","    output = self.encoder(noisy)\n","    n, c, h, w = output.size()\n","\n","    lnt_vec = self.bottleneck0(output.view(-1, c*h*w))\n","\n","    output = self.decoder(self.bottleneck1(lnt_vec).view(n, c, h, w))\n","\n","    return lnt_vec, noisy, output"]},{"cell_type":"markdown","metadata":{"id":"3Wk4_cBzQU19"},"source":["## Train DL Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0QJcgBk-QSsg"},"outputs":[],"source":["from torch.utils.data import DataLoader\n","from torch import optim\n","\n","from torchsummary import summary\n","\n","from tqdm import tqdm"]},{"cell_type":"markdown","metadata":{"id":"phpTOt47RjcB"},"source":["### Fix Seed"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"81NJ5JxbRnaU"},"outputs":[],"source":["import random\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o8F_Z5d3RlH-"},"outputs":[],"source":["def fix_seed(seed) :\n","  random.seed(seed)\n","  np.random.seed(seed)\n","  torch.manual_seed(seed)\n","  torch.cuda.manual_seed(seed)\n","  torch.cuda.manual_seed_all(seed)\n","  torch.backends.cudnn.deterministic = True\n","  torch.backends.cudnn.benchmark = False"]},{"cell_type":"markdown","metadata":{"id":"Jh4VCYXSswFY"},"source":["## Create Average Meter Instance"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oGUnMpzusxqw"},"outputs":[],"source":["class AverageMeter(object):\n","  def __init__(self):\n","    self.reset()\n","\n","  def reset(self):\n","    self.val = 0\n","    self.avg = 0\n","    self.sum = 0\n","    self.count = 0\n","\n","  def update(self, val, n=1):\n","    self.val = val\n","    self.sum += val*n\n","    self.count += n\n","    self.avg = self.sum / self.count"]},{"cell_type":"markdown","metadata":{"id":"lhJ28-fU6Zk7"},"source":["## Training Code as a Function (Abstraction)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Toe0P0WH6c9p"},"outputs":[],"source":["def train(opt, train_dataset, test_dataset, MyModel, criterion) :\n","  fix_seed(opt[\"seed\"])\n","\n","  train_dataloader = DataLoader(train_dataset, batch_size=opt[\"batch_size\"], shuffle=True, drop_last=True)\n","  test_dataloader = DataLoader(test_dataset, batch_size=opt[\"batch_size\"], shuffle=False, drop_last=False)\n","\n","  fix_seed(opt[\"seed\"])\n","  model = MyModel(opt)\n","  if opt[\"cuda\"] :\n","    model = model.cuda()\n","\n","  summary(model, (opt[\"input_dim\"], opt[\"input_shape\"], opt[\"input_shape\"]))\n","\n","  optimizer = optim.Adam(model.parameters(), lr=opt[\"lr\"])\n","\n","  train_loss, test_loss = AverageMeter(), AverageMeter()\n","  train_loss_list, test_loss_list = [], []\n","  best_loss = torch.inf\n","\n","  for epoch in range(1, opt[\"epochs\"]+1) :\n","    train_bar = tqdm(train_dataloader)\n","    train_loss.reset()\n","\n","    for data in train_bar :\n","      input, _ = data\n","      if opt[\"cuda\"] :\n","        input = input.cuda()\n","\n","      optimizer.zero_grad()\n","\n","      pred = model(input)\n","\n","      loss = criterion(pred[-1], input)\n","      loss.backward()\n","\n","      optimizer.step()\n","\n","      train_loss.update(loss.item(), opt[\"batch_size\"])\n","      train_bar.set_description(desc=f\"[{epoch}/{opt['epochs']}] [Train] < Loss:{train_loss.avg:.6f} >\")\n","\n","    train_loss_list.append(train_loss.avg)\n","\n","    test_bar = tqdm(test_dataloader)\n","    test_loss.reset()\n","\n","    for data in test_bar :\n","      input, _ = data\n","      if opt[\"cuda\"] :\n","        input = input.cuda()\n","\n","      model.eval()\n","      with torch.no_grad() :\n","        pred = model(input)\n","        loss = criterion(pred[-1], input)\n","\n","        test_loss.update(loss.item(), opt[\"batch_size\"])\n","\n","        test_bar.set_description(desc=f\"[{epoch}/{opt['epochs']}] [Test] < Loss:{test_loss.avg:.6f} >\")\n","\n","    test_loss_list.append(test_loss.avg)\n","\n","    if test_loss.avg < best_loss :\n","      best_loss = test_loss.avg\n","      torch.save(model.state_dict(), \"best_model.pth\")\n","\n","    torch.save(model.state_dict(), \"latest_model.pth\")\n","\n","  return (train_loss_list, test_loss_list)"]},{"cell_type":"markdown","metadata":{"id":"ttFH7GYJq6c3"},"source":["## Create Training Option (Hyperparameter) Dictionary"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tXzQHG9aq9xB"},"outputs":[],"source":["opt = {\"input_shape\":32,\n","       \"seed\":42,\n","       \"input_dim\":1,\n","       \"hidden_dim\":64,\n","       \"batch_size\":16,\n","       \"lr\":1e-4,\n","       \"epochs\":10,\n","       \"cuda\":torch.cuda.is_available()}"]},{"cell_type":"markdown","metadata":{"id":"VpE3M2q67qRu"},"source":["## Train Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yV7Jgs_77c57"},"outputs":[],"source":["loss_list = train(opt, train_dataset, test_dataset, MyModel, nn.L1Loss())"]},{"cell_type":"markdown","metadata":{"id":"XrgUhJC67uzu"},"source":["## Plot Training vs. Test Loss Graph"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_lIUGO11pAtu"},"outputs":[],"source":["import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mLsjFs3K7uzv"},"outputs":[],"source":["plt.figure(figsize=(20,10))\n","\n","plt.plot(np.arange(0, opt[\"epochs\"], 1), loss_list[0], label=\"Training Loss\")\n","plt.plot(np.arange(0, opt[\"epochs\"], 1), loss_list[1], label=\"Test Loss\")\n","\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"L1 Loss\")\n","plt.legend(loc=\"best\")\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"RP4jlNz2e42r"},"source":["## Extract Latent Vector"]},{"cell_type":"markdown","metadata":{"id":"5D-ZF3NhfGkO"},"source":["### Load Trained Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lxfxB9W1fIPE"},"outputs":[],"source":["weights = torch.load(\"/content/best_model.pth\")\n","\n","model = MyModel(opt)\n","model.load_state_dict(weights)\n","if opt[\"cuda\"] :\n","  model = model.cuda()"]},{"cell_type":"markdown","metadata":{"id":"8jjN8rSngATu"},"source":["### Get Model Structure"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z_vtvoYCfOgg"},"outputs":[],"source":["print(model)"]},{"cell_type":"markdown","metadata":{"id":"jKM5ipJXgDEZ"},"source":["### Load Test Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qzOVvKahfPCx"},"outputs":[],"source":["test_dataloader = DataLoader(test_dataset, batch_size=opt[\"batch_size\"], shuffle=False, drop_last=False)"]},{"cell_type":"markdown","metadata":{"id":"5hxQXQzpgEDq"},"source":["### Create Dictionary Instance for Saving Result"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DnOuCtOEf5eN"},"outputs":[],"source":["class_dict = {0:[], 1:[], 2:[], 3:[], 4:[], 5:[], 6:[], 7:[], 8:[], 9:[]}"]},{"cell_type":"markdown","metadata":{"id":"CfJybQL2gHUB"},"source":["### Add Result"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fmP6OP91mjqk"},"outputs":[],"source":["import cv2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RX3wQ7Qnnucv"},"outputs":[],"source":["%mkdir \"output_samples\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rg3_axMHfWcg"},"outputs":[],"source":["num_sample = 0\n","\n","for input, target in test_dataloader :\n","  if opt[\"cuda\"] :\n","    input = input.cuda()\n","    lnt_vec, noisy, output = model(input)\n","\n","  for i, label in enumerate(target) :\n","    class_dict[int(label)].append(lnt_vec[i].view(-1).detach().cpu().numpy())\n","\n","    sample_noisy = noisy[i].squeeze(0).detach().cpu().numpy()\n","    sample_output = output[i].squeeze(0).detach().cpu().numpy()\n","    sample_target = input[i].squeeze(0).detach().cpu().numpy()\n","\n","    sample_noisy = np.clip(sample_noisy*225, 0, 255)\n","    sample_output = np.clip(sample_output*225, 0, 255)\n","    sample_target = np.clip(sample_target*225, 0, 255)\n","\n","    concat = np.hstack((sample_noisy, sample_output, sample_target))\n","\n","    cv2.imwrite(f\"output_samples/sample_{num_sample}.png\", concat)\n","    num_sample += 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IWeRK_fucS_r"},"outputs":[],"source":["class_dict"]},{"cell_type":"markdown","metadata":{"id":"dtnr66aClFmj"},"source":["### Visualize Result"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3YUP9bwZcbO8"},"outputs":[],"source":["plt.figure(figsize=(10,10))\n","\n","for i in range(10) :\n","  x_list, y_list = [], []\n","  for sub_lnt_vec in class_dict[i] :\n","    x_list.append(sub_lnt_vec[0])\n","    y_list.append(sub_lnt_vec[1])\n","  plt.scatter(x_list, y_list, label=f\"class-{i}\", s=10)\n","\n","plt.legend(loc=\"best\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-l4XfDj5rdC8"},"outputs":[],"source":["concat = []\n","\n","for i in range(10) :\n","  sub_concat = []\n","  for j in range(10) :\n","    sub_concat.append(cv2.imread(f\"/content/output_samples/sample_{i*10+j}.png\"))\n","  concat.append(np.vstack(sub_concat))\n","\n","concat = np.hstack(concat)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kx2358DvmMUp"},"outputs":[],"source":["plt.figure(figsize=(20,20))\n","plt.imshow(concat)\n","plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}