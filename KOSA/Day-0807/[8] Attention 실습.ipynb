{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Attention"],"metadata":{"id":"f-WyqLE2aw1c"}},{"cell_type":"markdown","source":["입력 시퀀스 전체에서 중요한 정보를 선택적으로 참조할 수 있도록 하는 구조\n","\n","Seq2Seq 구조의 디코더에서 출력을 계산할 때 인코더의 hidden state 출력을 모두 사용"],"metadata":{"id":"bgapJBOaa1Sy"}},{"cell_type":"markdown","source":["## 장점\n"],"metadata":{"id":"o-nlUAoRbBCA"}},{"cell_type":"markdown","source":["긴 시퀀스 처리 능력 향상\n","- 고정된 크기의 컨텍스트 벡터를 사용하지 않기 때문에 긴 시퀀스에서도 중요한 정보를 놓치지 않고 사용할 수 있음\n","\n","정렬 문제 해결\n","- Seq2Seq 모델에서 입력과 출력 시퀀스 간의 단어 정렬 문제가 발생할 수 있는데, Attention은 각 단어 간의 상관관계를 학습하여 이를 해결함\n","\n","해석 가능\n","- Attention 가중치를 통해 모델의 어느 부분에 집중하고 있는지 확인할 수 있음"],"metadata":{"id":"yAjDotOTbErj"}},{"cell_type":"markdown","source":["## 단점"],"metadata":{"id":"r7Em_406bI-Q"}},{"cell_type":"markdown","source":["연산량 증가\n","- Attention 메커니즘은 추가적인 연산을 요구하므로 모델의 복잡성이 증가함. 특히 대용량 데이터셋에서 계산 비용이 높아짐\n","\n","메모리 소모\n","- 모든 입력 시퀀스를 저장해야 함, 시퀀스 길이가 길어질수록 메모리 사용량이 급격히 증가함\n","\n","훈련 속도 저하\n","- 모델이 복잡해지는 만큼 학습 속도가 느려짐\n"],"metadata":{"id":"4kB0bZlgbKJm"}},{"cell_type":"markdown","source":["## 종류"],"metadata":{"id":"oeeFKq9SbMky"}},{"cell_type":"markdown","source":["### 바다나우 어텐션 (Bahdanau Attention)\n"],"metadata":{"id":"1CdxcmBEbPHV"}},{"cell_type":"markdown","source":["Hidden state 결함\n","- 디코더의 이전 은닉 상태와 인코더의 각 은닉 상태를 결합한 후 비선형 변환을 통해 어텐션 가중치를 계산\n","\n","Additive 방식\n","- 디코더 은닉 상태 계산 이전에 어텐션 적용\n","- 은닉 상태를 더한 후, 특정 가중치 행렬을 사용하여 점수를 계산"],"metadata":{"id":"poQZG0S2bQCv"}},{"cell_type":"markdown","source":["### 룽 어텐션 (Luong Attention)\n"],"metadata":{"id":"tBap2qF2bRm0"}},{"cell_type":"markdown","source":["은닉 상태 내적\n","- 디코더의 현재 은닉 상태와 인코더의 은닉 상태 간의 내역을 사용해 어텐션 가중치를 계산. 바다나우 어텐션보다 계산이 효율적임\n","\n","Multiplicative 방식\n","- 디코더 은닉 상태 계산 이후에 어텐션 적용\n","- 두 은닉 상태를 내적하는 방식으로 컨텍스트 벡터 생성"],"metadata":{"id":"DDFt_LvRbTIU"}},{"cell_type":"markdown","source":["## 바다나우 어텐션 구현"],"metadata":{"id":"o4i7ieE-bYih"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","class BahdanauAttention(nn.Module):\n","    def __init__(self, hidden_size):\n","        super(BahdanauAttention, self).__init__()\n","        self.W1 = nn.Linear(hidden_size, hidden_size)\n","        self.W2 = nn.Linear(hidden_size, hidden_size)\n","        self.V = nn.Linear(hidden_size, 1)\n","\n","    def forward(self, hidden, encoder_outputs):\n","        # hidden: [batch_size, hidden_size]\n","        # encoder_outputs: [batch_size, seq_len, hidden_size]\n","\n","        hidden = hidden.unsqueeze(1)  # [batch_size, 1, hidden_size]\n","        score = self.V(torch.tanh(self.W1(encoder_outputs) + self.W2(hidden))) # [batch_size,seq_len,1]\n","\n","        attn_weights = torch.softmax(score, dim=1)  # [batch_size, seq_len, 1]\n","        context_vector = attn_weights * encoder_outputs  # [batch_size, seq_len, hidden_size]\n","        context_vector = torch.sum(context_vector, dim=1)  # [batch_size, hidden_size]\n","\n","        return context_vector, attn_weights"],"metadata":{"id":"Wvdyr_Dkbb0w","executionInfo":{"status":"ok","timestamp":1754546991287,"user_tz":-540,"elapsed":4114,"user":{"displayName":"서현택","userId":"13776042586561896178"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["## 룽 어텐션 구현"],"metadata":{"id":"GYAySu-jbdx7"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","class LuongAttention(nn.Module):\n","    def __init__(self, hidden_size):\n","        super(LuongAttention, self).__init__()\n","        self.attn = nn.Linear(hidden_size, hidden_size)\n","\n","    def forward(self, hidden, encoder_outputs):\n","        # hidden: [batch_size, hidden_size]\n","        # encoder_outputs: [batch_size, seq_len, hidden_size]\n","\n","        # 어텐션 가중치 계산\n","        hidden = self.attn(hidden).unsqueeze(1)  # [batch_size, 1, hidden_size]\n","        scores = torch.bmm(hidden, encoder_outputs.transpose(1, 2))  # [batch_size, 1, seq_len]\n","        attn_weights = F.softmax(scores, dim=2)  # [batch_size, 1, seq_len]\n","\n","        # 컨텍스트 벡터 계산\n","        context = torch.bmm(attn_weights, encoder_outputs)  # [batch_size, 1, hidden_size]\n","        return context, attn_weights"],"metadata":{"id":"LJf8_dGkbfKK","executionInfo":{"status":"ok","timestamp":1754546991289,"user_tz":-540,"elapsed":7,"user":{"displayName":"서현택","userId":"13776042586561896178"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["## Attention 기반 번역 모델 구현"],"metadata":{"id":"LSfs9AL8boo4"}},{"cell_type":"markdown","source":["### 인코더 클래스"],"metadata":{"id":"YNDKGlUObuYx"}},{"cell_type":"code","execution_count":4,"metadata":{"id":"uRfBopPZZlrN","executionInfo":{"status":"ok","timestamp":1754546991291,"user_tz":-540,"elapsed":7,"user":{"displayName":"서현택","userId":"13776042586561896178"}}},"outputs":[],"source":["class Encoder(nn.Module):\n","    def __init__(self, input_vocab_size, embed_size, hidden_size, num_layers=1):\n","        super(Encoder, self).__init__()\n","        self.embedding = nn.Embedding(input_vocab_size, embed_size)\n","        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n","\n","    def forward(self, x):\n","        # x: [batch_size, seq_len]\n","        embedded = self.embedding(x)  # [batch_size, seq_len, embed_size]\n","        outputs, (hidden, cell) = self.lstm(embedded)  # outputs: [batch_size, seq_len, hidden_size]\n","        return outputs, (hidden, cell)"]},{"cell_type":"markdown","source":["### 디코더 클래스"],"metadata":{"id":"87Uek4YQbx1V"}},{"cell_type":"code","source":["import torch.nn.functional as F\n","class Decoder(nn.Module):\n","    def __init__(self, target_vocab_size, embed_size, hidden_size, num_layers=1):\n","        super(Decoder, self).__init__()\n","        self.embedding = nn.Embedding(target_vocab_size, embed_size)\n","        self.lstm = nn.LSTM(embed_size + hidden_size, hidden_size, num_layers, batch_first=True)\n","        self.attention = BahdanauAttention(hidden_size)\n","        self.fc = nn.Linear(hidden_size, target_vocab_size)\n","\n","    def forward(self, input_step, hidden, cell, encoder_outputs):\n","        embedded = self.embedding(input_step)  # [batch_size, embed_size]\n","        embedded = embedded.unsqueeze(1)  # [batch_size, 1, embed_size]\n","\n","        context_vector, attn_weights = self.attention(hidden[-1], encoder_outputs)\n","\n","        lstm_input = torch.cat((embedded, context_vector.unsqueeze(1)), dim=2)  # [batch_size, 1, embed_size + hidden_size]\n","        output, (hidden, cell) = self.lstm(lstm_input, (hidden, cell))\n","\n","\n","        output = self.fc(output.squeeze(1))  # [batch_size, target_vocab_size]\n","        output = F.log_softmax(output, dim=1)\n","        return output, hidden, cell, attn_weights"],"metadata":{"id":"UtLp9r4ibxPl","executionInfo":{"status":"ok","timestamp":1754546991291,"user_tz":-540,"elapsed":5,"user":{"displayName":"서현택","userId":"13776042586561896178"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["### Seq2Seq 클래스 정의"],"metadata":{"id":"P1RSUvAEcCv9"}},{"cell_type":"code","source":["import random\n","class Seq2Seq(nn.Module):\n","    def __init__(self, encoder, decoder, device):\n","        super(Seq2Seq, self).__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.device = device\n","\n","    def forward(self, source, target, teacher_forcing_ratio=0.5):\n","        batch_size = source.size(0)\n","        tgt_len = target.size(1)\n","        tgt_vocab_size = self.decoder.fc.out_features\n","\n","        outputs = torch.zeros(batch_size, tgt_len, tgt_vocab_size).to(self.device)\n","        encoder_outputs, (hidden, cell) = self.encoder(source)\n","\n","        input_step = target[:, 0]  # [batch_size]\n","\n","        for t in range(1, tgt_len):\n","            # 디코더를 통해 다음 단어 예측\n","            output, hidden, cell, attn_weights = self.decoder(input_step, hidden, cell, encoder_outputs)\n","            outputs[:, t] = output\n","            # 교사 강요 적용 여부 결정\n","            teacher_force = random.random() < teacher_forcing_ratio\n","            top1 = output.argmax(1)  # [batch_size]\n","            input_step = target[:, t] if teacher_force else top1\n","        return outputs"],"metadata":{"id":"yKsLgtrzb0Q7","executionInfo":{"status":"ok","timestamp":1754546991293,"user_tz":-540,"elapsed":1,"user":{"displayName":"서현택","userId":"13776042586561896178"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["# 실습"],"metadata":{"id":"2zBOmMnkccxv"}},{"cell_type":"markdown","source":["강의자료를 바탕으로 어텐션 구조를 적용한 Seq2Seq 훈련 코드를 작성하고 훈련을 수행해보시오"],"metadata":{"id":"34PTVvHiceNZ"}},{"cell_type":"code","source":["data = [\n","    ('je suis etudiant', 'i am a student'),\n","    ('j aime le football', 'i love football'),\n","    ('il fait beau aujourd hui', 'it is nice today'),\n","    ('je mange une pomme', 'i eat an apple'),\n","    ('nous aimons apprendre', 'we love learning'),\n","    ('je vais à l école', 'i go to school'),\n","    ('tu es mon ami', 'you are my friend'),\n","    ('elle lit un livre', 'she is reading a book'),\n","    ('il écrit une lettre', 'he is writing a letter'),\n","    ('nous regardons un film', 'we are watching a movie'),\n","    ('vous parlez français', 'you speak french'),\n","    ('ils jouent au tennis', 'they play tennis'),\n","    ('je fais du sport', 'i do sports'),\n","    ('tu écoutes de la musique', 'you listen to music'),\n","    ('elle cuisine un gâteau', 'she is baking a cake'),\n","    ('il conduit une voiture', 'he is driving a car'),\n","    ('nous visitons le musée', 'we are visiting the museum'),\n","    ('vous aimez la plage', 'you love the beach'),\n","    ('ils dansent bien', 'they dance well'),\n","    ('je prends le train', 'i take the train'),\n","    ('tu joues de la guitare', 'you play the guitar'),\n","    ('elle dessine un portrait', 'she draws a portrait'),\n","    ('il apprend l anglais', 'he learns english'),\n","    ('nous voyageons en avion', 'we travel by plane'),\n","    ('vous travaillez dur', 'you work hard'),\n","    ('ils étudient la biologie', 'they study biology'),\n","    ('je bois du café', 'i drink coffee'),\n","    ('tu manges du pain', 'you eat bread'),\n","    ('elle porte une robe', 'she wears a dress'),\n","    ('il lit le journal', 'he reads the newspaper'),\n","    ('nous aimons la nature', 'we love nature'),\n","    ('vous prenez le bus', 'you take the bus'),\n","    ('ils chantent une chanson', 'they sing a song'),\n","    ('je visite Paris', 'i visit paris'),\n","    ('tu écris un poème', 'you write a poem'),\n","    ('elle étudie la médecine', 'she studies medicine'),\n","    ('il fait ses devoirs', 'he does his homework'),\n","    ('nous préparons le dîner', 'we prepare dinner'),\n","    ('vous jouez au basketball', 'you play basketball'),\n","    ('ils regardent la télévision', 'they watch television'),\n","    ('je dors bien', 'i sleep well'),\n","    ('tu travailles dans un bureau', 'you work in an office'),\n","    ('elle nage dans la piscine', 'she swims in the pool'),\n","    ('il se réveille tôt', 'he wakes up early'),\n","    ('nous chantons ensemble', 'we sing together'),\n","    ('vous écrivez des emails', 'you write emails'),\n","    ('ils jouent aux cartes', 'they play cards'),\n","    ('je visite un parc', 'i visit a park'),\n","    ('tu fais du vélo', 'you ride a bike'),\n","    ('elle regarde les étoiles', 'she watches the stars'),\n","    ('il monte les escaliers', 'he climbs the stairs'),\n","    ('nous lisons un roman', 'we read a novel'),\n","    ('vous écoutez la radio', 'you listen to the radio'),\n","    ('ils se promènent en ville', 'they walk around the city'),\n","    ('je cours dans le parc', 'i run in the park'),\n","    ('tu achètes des légumes', 'you buy vegetables'),\n","    ('elle joue au volley', 'she plays volleyball'),\n","    ('il nettoie la maison', 'he cleans the house'),\n","    ('nous prenons le petit déjeuner', 'we have breakfast'),\n","    ('vous apprenez une nouvelle langue', 'you learn a new language'),\n","    ('ils font la cuisine', 'they cook'),\n","    ('je dessine une maison', 'i draw a house'),\n","    ('tu regardes un documentaire', 'you watch a documentary'),\n","    ('elle visite un château', 'she visits a castle'),\n","    ('il photographie le paysage', 'he photographs the landscape'),\n","    ('nous organisons une fête', 'we organize a party'),\n","    ('vous jouez aux échecs', 'you play chess'),\n","    ('ils courent ensemble', 'they run together'),\n","    ('je regarde un match de football', 'i watch a football match'),\n","    ('tu lis un magazine', 'you read a magazine'),\n","    ('elle prépare une salade', 'she makes a salad'),\n","    ('il voyage en train', 'he travels by train'),\n","    ('nous faisons du shopping', 'we go shopping'),\n","    ('vous dansez au club', 'you dance at the club'),\n","    ('ils étudient l histoire', 'they study history'),\n","    ('je visite le marché', 'i visit the market'),\n","    ('tu achètes un cadeau', 'you buy a gift'),\n","    ('elle travaille dans une école', 'she works in a school'),\n","    ('il joue du piano', 'he plays the piano'),\n","    ('nous regardons le coucher du soleil', 'we watch the sunset'),\n","    ('vous apprenez à cuisiner', 'you learn to cook'),\n","    ('ils se reposent après le travail', 'they rest after work'),\n","    ('je prends des photos', 'i take photos'),\n","    ('tu fais de la natation', 'you go swimming'),\n","    ('elle sourit toujours', 'she always smiles'),\n","    ('il étudie à l université', 'he studies at the university'),\n","    ('nous visitons nos amis', 'we visit our friends'),\n","    ('vous mangez au restaurant', 'you eat at the restaurant'),\n","    ('ils jouent dans le jardin', 'they play in the garden'),\n","    ('je prends des notes', 'i take notes'),\n","    ('tu conduis prudemment', 'you drive carefully'),\n","    ('elle chante magnifiquement', 'she sings beautifully'),\n","    ('il lit un roman policier', 'he reads a detective novel'),\n","    ('nous partons en vacances', 'we go on vacation'),\n","    ('vous regardez les étoiles', 'you watch the stars'),\n","    ('ils écoutent de la musique classique', 'they listen to classical music'),\n","    ('je prépare un café', 'i make a coffee'),\n","    ('tu joues avec ton chien', 'you play with your dog'),\n","    ('elle porte des lunettes', 'she wears glasses'),\n","    ('il aime le chocolat', 'he loves chocolate')\n","]"],"metadata":{"id":"DGXtWh8JcMTE","executionInfo":{"status":"ok","timestamp":1754546991304,"user_tz":-540,"elapsed":2,"user":{"displayName":"서현택","userId":"13776042586561896178"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["import re\n","import unicodedata\n","\n","# 문장 전처리 함수\n","def preprocess_sentence(sentence):\n","    # 악센트 제거\n","    sentence = ''.join(c for c in unicodedata.normalize('NFD', sentence)\n","                       if unicodedata.category(c) != 'Mn')\n","    # 소문자 변환\n","    sentence = sentence.lower()\n","    # 특수 문자 제거\n","    sentence = re.sub(r\"[^a-zA-Z0-9]+\", \" \", sentence)\n","    # 양쪽 공백 제거\n","    sentence = sentence.strip()\n","    return sentence\n","\n","# 입력과 출력 문장 전처리\n","input_texts = []\n","target_texts = []\n","input_vocab = set()\n","target_vocab = set()\n","\n","for input_sentence, target_sentence in data:\n","    input_sentence = preprocess_sentence(input_sentence)\n","    target_sentence = preprocess_sentence(target_sentence)\n","    # 시작과 종료 토큰 추가\n","    target_sentence = '<sos> ' + target_sentence + ' <eos>'\n","    input_texts.append(input_sentence)\n","    target_texts.append(target_sentence)\n","    # 어휘 사전 생성\n","    input_vocab.update(input_sentence.split(' '))\n","    target_vocab.update(target_sentence.split(' '))\n","\n","# 단어 사전에 PAD 토큰 추가\n","input_vocab = ['<pad>'] + sorted(input_vocab)\n","target_vocab = ['<pad>'] + sorted(target_vocab)\n","\n","# 단어와 인덱스 매핑\n","input_word2idx = {word: idx for idx, word in enumerate(input_vocab)}\n","input_idx2word = {idx: word for idx, word in enumerate(input_vocab)}\n","\n","target_word2idx = {word: idx for idx, word in enumerate(target_vocab)}\n","target_idx2word = {idx: word for idx, word in enumerate(target_vocab)}\n","\n","# 최대 시퀀스 길이 계산\n","max_input_len = max(len(seq.split(' ')) for seq in input_texts)\n","max_target_len = max(len(seq.split(' ')) for seq in target_texts)\n","\n","# 시퀀스를 인덱스 시퀀스로 변환하고 패딩 적용\n","def text_to_sequence(text, word2idx, max_len):\n","    seq = [word2idx[word] for word in text.split(' ')]\n","    seq += [word2idx['<pad>']] * (max_len - len(seq))\n","    return seq\n","\n","input_sequences = [text_to_sequence(text, input_word2idx, max_input_len) for text in input_texts]\n","target_sequences = [text_to_sequence(text, target_word2idx, max_target_len) for text in target_texts]\n","\n","\n","print(\"입력 시퀀스 예시:\", input_sequences[0])\n","print(\"출력 시퀀스 예시:\", target_sequences[0])"],"metadata":{"id":"DJnbmGsQcqtJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1754546991335,"user_tz":-540,"elapsed":22,"user":{"displayName":"서현택","userId":"13776042586561896178"}},"outputId":"3067cc2e-0cfd-4af8-961f-a84bec28b438"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["입력 시퀀스 예시: [91, 173, 72, 0, 0, 0]\n","출력 시퀀스 예시: [2, 71, 6, 3, 138, 1, 0]\n"]}]},{"cell_type":"code","source":["import torch.optim as optim\n","\n","# 하이퍼파라미터 설정\n","input_vocab_size = len(input_vocab)\n","target_vocab_size = len(target_vocab)\n","embed_size = 16\n","hidden_size = 32\n","learning_rate = 0.001\n","num_epochs = 5000\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# 모델 초기화\n","encoder = Encoder(input_vocab_size, embed_size, hidden_size).to(device)\n","decoder = Decoder(target_vocab_size, embed_size, hidden_size).to(device)\n","model = Seq2Seq(encoder, decoder, device).to(device)\n","\n","# 손실 함수와 최적화기 정의\n","criterion = nn.CrossEntropyLoss(ignore_index=target_word2idx['<pad>'])\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)"],"metadata":{"id":"qviIao6O_Cun","executionInfo":{"status":"ok","timestamp":1754546996512,"user_tz":-540,"elapsed":5176,"user":{"displayName":"서현택","userId":"13776042586561896178"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# 입력과 출력 시퀀스를 텐서로 변환\n","input_tensor = torch.LongTensor(input_sequences).to(device)\n","target_tensor = torch.LongTensor(target_sequences).to(device)\n","\n","# 학습 루프\n","for epoch in range(1, num_epochs + 1):\n","    optimizer.zero_grad()\n","    output = model(input_tensor, target_tensor)\n","    # 출력 차원 변경: [batch_size * target_len, target_vocab_size]\n","    output_dim = output.shape[-1]\n","    output = output[:, 1:].reshape(-1, output_dim)\n","    target = target_tensor[:, 1:].reshape(-1)\n","    loss = criterion(output, target)\n","    loss.backward()\n","    optimizer.step()\n","\n","    if epoch % 500 == 0:\n","        print(f'Epoch: {epoch}, Loss: {loss.item():.4f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9PCZXxwg_E6S","executionInfo":{"status":"ok","timestamp":1754547074783,"user_tz":-540,"elapsed":78268,"user":{"displayName":"서현택","userId":"13776042586561896178"}},"outputId":"d469d446-df17-4c61-cf9c-893c318e494a"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 500, Loss: 0.8891\n","Epoch: 1000, Loss: 0.1156\n","Epoch: 1500, Loss: 0.0371\n","Epoch: 2000, Loss: 0.0180\n","Epoch: 2500, Loss: 0.0105\n","Epoch: 3000, Loss: 0.0067\n","Epoch: 3500, Loss: 0.0045\n","Epoch: 4000, Loss: 0.0031\n","Epoch: 4500, Loss: 0.0022\n","Epoch: 5000, Loss: 0.0016\n"]}]},{"cell_type":"code","source":["def translate(sentence):\n","    model.eval()\n","    sentence = preprocess_sentence(sentence)\n","    sequence = text_to_sequence(sentence, input_word2idx, max_target_len)\n","    sequence = torch.LongTensor(sequence).unsqueeze(0).to(device)\n","    with torch.no_grad():\n","        encoder_outputs, (hidden, cell) = model.encoder(sequence)\n","        input_token = torch.LongTensor([target_word2idx['<sos>']]).to(device)\n","        result = []\n","        for _ in range(20):\n","            output, hidden, cell, attn_weights = model.decoder(input_token, hidden, cell, encoder_outputs)\n","            top1 = output.argmax(1)\n","            if top1.item() == target_word2idx['<eos>']:\n","                break\n","            result.append(top1.item())\n","            input_token = top1\n","    translated_sentence = ' '.join([target_idx2word[idx] for idx in result])\n","    return translated_sentence"],"metadata":{"id":"__Q_az3T_Hcp","executionInfo":{"status":"ok","timestamp":1754547083567,"user_tz":-540,"elapsed":2,"user":{"displayName":"서현택","userId":"13776042586561896178"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# 예측 예시\n","test_sentences = [\n","    'je suis etudiant',\n","    'il fait beau aujourd hui',\n","    'nous aimons apprendre'\n","]\n","\n","for sentence in test_sentences:\n","    translation = translate(sentence)\n","    print(f\"입력 문장: {sentence}\")\n","    print(f\"번역 문장: {translation}\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HYiFuQW__cak","executionInfo":{"status":"ok","timestamp":1754547086806,"user_tz":-540,"elapsed":24,"user":{"displayName":"서현택","userId":"13776042586561896178"}},"outputId":"2a8dfa5a-65c6-41de-cd3d-84aeda83fbc5"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["입력 문장: je suis etudiant\n","번역 문장: i am a student\n","\n","입력 문장: il fait beau aujourd hui\n","번역 문장: it is nice today\n","\n","입력 문장: nous aimons apprendre\n","번역 문장: we love learning\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"kaaHuTLr_eW9","executionInfo":{"status":"aborted","timestamp":1754547074897,"user_tz":-540,"elapsed":2,"user":{"displayName":"서현택","userId":"13776042586561896178"}}},"execution_count":null,"outputs":[]}]}